<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Adding Derivatives to Your Components &mdash; OpenMDAO Documentation</title>
    
    <link rel="stylesheet" href="../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.13.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="OpenMDAO Documentation" href="../../index.html" />
    <link rel="up" title="Simple Optimization" href="index.html" />
    <link rel="next" title="Choosing an Optimizer" href="optimizers.html" />
    <link rel="prev" title="Recording Your Inputs and Outputs" href="case_recorders.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="optimizers.html" title="Choosing an Optimizer"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="case_recorders.html" title="Recording Your Inputs and Outputs"
             accesskey="P">previous</a> |</li>
  <li><a href="http://openmdao.org">OpenMDAO Home</a> &raquo;</li>
  
        <li><a href="../../index.html">OpenMDAO Documentation v0.13.0</a> &raquo;</li>

          <li><a href="../index.html" >OpenMDAO Tutorials</a> &raquo;</li>
          <li><a href="index.html" accesskey="U">Simple Optimization</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="adding-derivatives-to-your-components">
<span id="index-0"></span><span id="id1"></span><h1>Adding Derivatives to Your Components<a class="headerlink" href="#adding-derivatives-to-your-components" title="Permalink to this headline">¶</a></h1>
<p>Many optimization algorithms make use of gradients. In our simple example
problem, the SLSQP driver estimates the gradient at various times during the
solution procedure by performing a local finite-difference step. Calculating
the gradient typically involves one or more executions of the objective
function depending on the finite difference method that is used. This, of
course, means that your model is executed additional times each iteration.</p>
<p>Sometimes the solution process can be sped up by having a component supply
its own derivatives. These derivatives may be analytical (as you will see in
this example), or they might be estimated by some other means. Additionally,
these derivatives can be more accurate than those estimated by finite
differencing the component, and they are not dependent on the right choice of
a step-size parameter.</p>
<p id="index-1">In OpenMDAO, derivatives can be specified in the component API by following
these two steps:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c">#  Define a ``list_deriv_vars`` function that tell openmdao which inputs and outputs you have derivatives w.r.t and of</span>
<span class="c">#. Define a ``provideJ`` method that calculates and returns the Jacobian.</span>
</pre></div>
</div>
<p>Let&#8217;s look at an example, using the Paraboloid component, to see how this would work in
practice. Starting with the original code, but calling our new
class <tt class="docutils literal"><span class="pre">ParaboloidDerivative</span></tt>, we have:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">array</span>

<span class="kn">from</span> <span class="nn">openmdao.main.api</span> <span class="kn">import</span> <span class="n">Component</span>
<span class="kn">from</span> <span class="nn">openmdao.lib.datatypes.api</span> <span class="kn">import</span> <span class="n">Float</span>

<span class="k">class</span> <span class="nc">ParaboloidDerivative</span><span class="p">(</span><span class="n">Component</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Evaluates the equation f(x,y) = (x-3)^2 + xy + (y+4)^2 - 3 &quot;&quot;&quot;</span>

    <span class="c"># set up interface to the framework</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">iotype</span><span class="o">=</span><span class="s">&#39;in&#39;</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s">&#39;The variable x&#39;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">Float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">iotype</span><span class="o">=</span><span class="s">&#39;in&#39;</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s">&#39;The variable y&#39;</span><span class="p">)</span>

    <span class="n">f_xy</span> <span class="o">=</span> <span class="n">Float</span><span class="p">(</span><span class="n">iotype</span><span class="o">=</span><span class="s">&#39;out&#39;</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s">&#39;F(x,y)&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The two function we need to add are <tt class="docutils literal"><span class="pre">list_deriv_vars</span></tt> and <tt class="docutils literal"><span class="pre">provideJ</span></tt>.
The first function indicates which derivatives you&#8217;re proving.
The order that you provide the variables in is important. The order of the variables
is important. The first set, the inputs, is given in the same order as the columns
of the Jacobian. The second set, the outputs, is given in the same order as the rows of the
Jacobian. The second function calculates and returns a matrix (the Jacobian)
of the derivatives, evaluated at the current state of the model.
The paraboloid model has two inputs and one output, so
the Jacobian is a 1 by 2 numpy array. If you linearized around the point (0,0)
then the Jacobian would look like:</p>
<table border="1" class="docutils">
<colgroup>
<col width="35%" />
<col width="35%" />
<col width="30%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">&nbsp;</th>
<th class="head"><strong>x</strong></th>
<th class="head"><strong>y</strong></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><strong>f_xy</strong></td>
<td>-6.0</td>
<td>8.0</td>
</tr>
</tbody>
</table>
<p>Here&#8217;s what the code to implement these derivatives looks like.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">list_deriv_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;specified the inputs and outputs where derivatives are defined&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">,</span> <span class="s">&#39;y&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;f_xy&#39;</span><span class="p">,)</span>

<span class="k">def</span> <span class="nf">provideJ</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate the Jacobian&quot;&quot;&quot;</span>

    <span class="n">df_dx</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">-</span> <span class="mf">6.0</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>
    <span class="n">df_dy</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">+</span> <span class="mf">8.0</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span>

    <span class="n">J</span> <span class="o">=</span> <span class="n">array</span><span class="p">([[</span><span class="n">df_dx</span><span class="p">,</span> <span class="n">df_dy</span><span class="p">]])</span>
    <span class="k">return</span> <span class="n">J</span>
</pre></div>
</div>
<p>So <tt class="docutils literal"><span class="pre">J</span></tt> is the Jacobian that OpenMDAO will use when assembling the system level derivatives. If
this component was part of a much larger model with other components, it only contributes
a small portion of the full Jacobian. OpenMDAO uses a numerical method developed by
<a class="reference external" href="http://mdolab.engin.umich.edu/content/review-and-unification-discrete-methods-computing-derivatives-single-and-multi-disciplinary">Martins and Hwang</a> [1]
to solve for the gradient of the full problem.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You don&#8217;t have to include all of the inputs and
outputs in the Jacobian. There is certainly no reason to provide the
derivative of inputs that are never hooked up to other
outputs or irrelevant to the gradient for some other reason. If you omit derivatives,
which end up being needed as part of the optimization OpenMDAO will throw an error
to alert you of problem.</p>
</div>
<p>The ParaboloidDerivative component can be placed into a model, and the
derivatives will be used with no changes required to the
OptimizationConstrained or OptimizationUnconstrained assembly at this point.
If the driver uses gradients and can take advantage of the
analytical ones you provide, then it will do so. Below is our model, using
the new component with derivatives. We put this model in a file called
<a class="reference download internal" href="../../_downloads/optimization_constrained_derivative.py"><tt class="xref download docutils literal"><span class="pre">optimization_constrained_derivative.py</span></tt></a>.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    optimization_constrained.py - Top level assembly for the problem.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c"># Perform an constrained optimization on our paraboloid component.</span>

<span class="kn">from</span> <span class="nn">openmdao.main.api</span> <span class="kn">import</span> <span class="n">Assembly</span>
<span class="kn">from</span> <span class="nn">openmdao.lib.drivers.api</span> <span class="kn">import</span> <span class="n">SLSQPdriver</span>

<span class="kn">from</span> <span class="nn">openmdao.examples.simple.paraboloid_derivative</span> <span class="kn">import</span> <span class="n">ParaboloidDerivative</span>

<span class="k">class</span> <span class="nc">OptimizationConstrained</span><span class="p">(</span><span class="n">Assembly</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constrained optimization of the Paraboloid Component.&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">configure</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new Assembly containing a Paraboloid and an optimizer&quot;&quot;&quot;</span>
                
        <span class="c"># Create Paraboloid component instances</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#39;paraboloid&#39;</span><span class="p">,</span> <span class="n">ParaboloidDerivative</span><span class="p">())</span>

        <span class="c"># Create Optimizer instance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#39;driver&#39;</span><span class="p">,</span> <span class="n">SLSQPdriver</span><span class="p">())</span>
        
        <span class="c"># Driver process definition</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">workflow</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#39;paraboloid&#39;</span><span class="p">)</span>
        
        <span class="c"># Optimizer Flags</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">iprint</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="c"># Objective </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="s">&#39;paraboloid.f_xy&#39;</span><span class="p">)</span>
        
        <span class="c"># Design Variables </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">add_parameter</span><span class="p">(</span><span class="s">&#39;paraboloid.x&#39;</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mf">50.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">50.</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">add_parameter</span><span class="p">(</span><span class="s">&#39;paraboloid.y&#39;</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mf">50.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">50.</span><span class="p">)</span>
        
        <span class="c"># Constraints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">add_constraint</span><span class="p">(</span><span class="s">&#39;paraboloid.x-paraboloid.y &gt;= 15.0&#39;</span><span class="p">)</span>
        
        
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span> <span class="c"># pragma: no cover         </span>

    <span class="kn">import</span> <span class="nn">time</span>
    
    <span class="n">opt_problem</span> <span class="o">=</span> <span class="n">OptimizationConstrained</span><span class="p">()</span>
    
    <span class="n">tt</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">opt_problem</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

    <span class="k">print</span> <span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span>
    <span class="k">print</span> <span class="s">&quot;Minimum found at (</span><span class="si">%f</span><span class="s">, </span><span class="si">%f</span><span class="s">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">opt_problem</span><span class="o">.</span><span class="n">paraboloid</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> \
                                         <span class="n">opt_problem</span><span class="o">.</span><span class="n">paraboloid</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">&quot;Elapsed time: &quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">tt</span><span class="p">,</span> <span class="s">&quot;seconds&quot;</span>
    
<span class="c"># end optimization_constrained.py</span>
</pre></div>
</div>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td>Martins, J. R. R. A., and Hwang, J. T., &#8220;Review and Unification of Methods for
Computing Derivatives of Multidisciplinary Computational Models,&#8221; <cite>AIAA Journal,</cite> 2013.</td></tr>
</tbody>
</table>
<div class="section" id="benchmarking">
<h2><em>Benchmarking</em><a class="headerlink" href="#benchmarking" title="Permalink to this headline">¶</a></h2>
<p>Sometimes it is useful to know how many times your component executes and
how many times it calculates its derivatives. OpenMDAO provides this
information for every component through a pair of counters: <tt class="docutils literal"><span class="pre">exec_count</span></tt>
is incremented whenever a component executes, and <tt class="docutils literal"><span class="pre">derivative_exec_count</span></tt>
is incremented whenever the derivatives are calculated. The following
example shows how they can be accessed and used.</p>
<div class="highlight-python"><div class="highlight"><pre>    &gt;&gt;&gt; # Paraboloid Model
    &gt;&gt;&gt;
    &gt;&gt;&gt; from openmdao.examples.simple.optimization_constrained import OptimizationConstrained
    &gt;&gt;&gt; model = OptimizationConstrained()
    &gt;&gt;&gt; model.run()
    &gt;&gt;&gt; print model.paraboloid.exec_count
    10
    &gt;&gt;&gt; print model.paraboloid.derivative_exec_count
    0
    &gt;&gt;&gt; # Paraboloid Model with analytical derivatives
    &gt;&gt;&gt;
    &gt;&gt;&gt; from openmdao.examples.simple.optimization_constrained_derivative import OptimizationConstrained
    &gt;&gt;&gt; model = OptimizationConstrained()
    &gt;&gt;&gt; model.run()
    &gt;&gt;&gt; print model.paraboloid.exec_count
    4
    &gt;&gt;&gt; print model.paraboloid.derivative_exec_count
    3
</pre></div>
</div>
<p>Here we&#8217;ve printed out the number of function and derivative executions for
the paraboloid examples, both without and with analytical derivatives.
Because this model is a simple equation, the advantage of using the
analytical derivative isn&#8217;t evident in a comparison of the clock time, but
the number of functional executions is much lower when you have them, at a
cost of a small number of derivative evaluations.</p>
<p>This concludes an introduction to OpenMDAO using a simple problem of
component creation and execution. The next tutorial introduces a problem with
more complexity and presents additional features of the framework.</p>
</div>
<div class="section" id="finite-difference">
<h2><em>Finite Difference</em><a class="headerlink" href="#finite-difference" title="Permalink to this headline">¶</a></h2>
<p>If you don&#8217;t specify any derivatives (you don&#8217;t define <tt class="docutils literal"><span class="pre">list_deriv_vars</span></tt> or <tt class="docutils literal"><span class="pre">provideJ</span></tt> functions) for your component, then OpenMDAO
will finite difference it during the calculation of the full model gradient. OpenMDAO
can identify groups of non-differentiable components to finite difference as a block.
Also, OpenMDAO can detect a non-differentiable connection between two differentiable
components (e.g, components passing a file or string) and will include both components
with the non-differentiables.</p>
<p>There are a number of ways to control how OpenMDAO finite differences your
components and your full model. Every driver contains a variable tree called
<tt class="docutils literal"><span class="pre">gradient_options</span></tt>. This tree contains the settings that control how that
driver performs a finite difference. Note that since each driver has one, it
is possible to use different settings for different drivers. Consider the same
example from above, but let&#8217;s see how you can change some settings.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">openmdao.examples.simple.optimization_constrained</span> <span class="kn">import</span> <span class="n">OptimizationConstrained</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OptimizationConstrained</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">gradient_options</span><span class="o">.</span><span class="n">fd_form</span> <span class="o">=</span> <span class="s">&#39;central&#39;</span>
<span class="n">model</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">gradient_options</span><span class="o">.</span><span class="n">fd_step</span> <span class="o">=</span> <span class="mf">1.0e-3</span>
<span class="n">model</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">gradient_options</span><span class="o">.</span><span class="n">fd_step_type</span> <span class="o">=</span> <span class="s">&#39;relative&#39;</span>
</pre></div>
</div>
<p>The default form for finite difference is a forward difference, but sometimes
you may want the second order accuracy of a central difference (and you are
fine with the extra execution per call.) The default stepsize is 1.0e-6,
which will not be adequate for your problem if your variable is very large or
small, so it is essential to choose this value carefully. Fiinally, the
default step type is <tt class="docutils literal"><span class="pre">'absolute'</span></tt>, but you may want to set it to <tt class="docutils literal"><span class="pre">'relative'</span></tt> for
variables that have a wider range of possible magnitudes. Relative
differencing calculates a step size by taking the current variable value and
multipying it by the <tt class="docutils literal"><span class="pre">fd_step</span></tt> value.</p>
<p>You can also tell a driver to ignore all analytic derivatives and just use finite
difference.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">openmdao.examples.simple.optimization_constrained</span> <span class="kn">import</span> <span class="n">OptimizationConstrained</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OptimizationConstrained</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">gradient_options</span><span class="o">.</span><span class="n">force_fd</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</div>
<p>When you use this setting, OpenMDAO will finite difference your problem from the inputs to the
outputs as one large block.</p>
<p>Finally, there are a couple of settings for the analytic solution of the system equations
that yields the derivatives. OpenMDAO uses Scipy&#8217;s GMRES solver, and it exposes both its
tolerance and its maximum iteration count to be controlled by the user.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">openmdao.examples.simple.optimization_constrained</span> <span class="kn">import</span> <span class="n">OptimizationConstrained</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OptimizationConstrained</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">gradient_options</span><span class="o">.</span><span class="n">atol</span> <span class="o">=</span> <span class="mf">1.0e-9</span>
<span class="n">model</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">gradient_options</span><span class="o">.</span><span class="n">maxiter</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
<p>For fine control of the finite difference stepsize, some of the global
settings can also be overriden by specifying them as metadata in the
<cite>Variable</cite> definition. Consider the following variables:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x1</span> <span class="o">=</span> <span class="n">Float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">iotype</span><span class="o">=</span><span class="s">&#39;in&#39;</span><span class="p">,</span> <span class="n">fd_step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">Float</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">iotype</span><span class="o">=</span><span class="s">&#39;in&#39;</span><span class="p">,</span> <span class="n">fd_step_type</span><span class="o">=</span><span class="s">&#39;relative&#39;</span><span class="p">)</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">Float</span><span class="p">(</span><span class="mf">1000.0</span><span class="p">,</span> <span class="n">iotype</span><span class="o">=</span><span class="s">&#39;in&#39;</span><span class="p">,</span> <span class="n">fd_step</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">fd_form</span><span class="o">=</span><span class="s">&#39;central&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, we have locally set the finite difference stepsize on x1 to 0.01. For x2,
we chose to use a relative stepsize instead of an absolute one, which means that the
global stepsize of 1.0e-6 that is set in the driver is applied to this variable as
a relative stepsize. Finally, x3 assigns a stepsize of 0.1, but a central difference
will be performed instead of a forward difference.</p>
<p>You may also want to force OpenMDAO to finite difference a component even though you
have defined derivatives for it. You can do this by setting its <tt class="docutils literal"><span class="pre">force_fd</span></tt> attribute
to True.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">top</span> <span class="o">=</span> <span class="n">set_as_top</span><span class="p">(</span><span class="n">Assembly</span><span class="p">())</span>
<span class="n">top</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#39;my_comp&#39;</span><span class="p">,</span> <span class="n">ParaboloidDerivative</span><span class="p">())</span>
<span class="n">top</span><span class="o">.</span><span class="n">my_comp</span><span class="o">.</span><span class="n">force_fd</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</div>
</div>
<div class="section" id="complex-step">
<h2><em>Complex Step</em><a class="headerlink" href="#complex-step" title="Permalink to this headline">¶</a></h2>
<p>You can also choose to calculate the derivatives with the Complex Step method instead of finite
difference. Its advantage over finite difference is that its accuracty is not sensitive to the choice of
stepsize. However, to use this method, your model needs to be able to operate on complex inputs and
produce complex outputs. This will already be true of most python modules, but your external codes
may need special modification to use complex step.</p>
<p>To use complex step to calculate the gradient during the paraboloid optimization:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">openmdao.examples.simple.optimization_constrained</span> <span class="kn">import</span> <span class="n">OptimizationConstrained</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OptimizationConstrained</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">gradient_options</span><span class="o">.</span><span class="n">fd_form</span> <span class="o">=</span> <span class="s">&#39;complex_step&#39;</span>
<span class="n">model</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">gradient_options</span><span class="o">.</span><span class="n">fd_step</span> <span class="o">=</span> <span class="mf">1.0e-3</span>
<span class="n">model</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">gradient_options</span><span class="o">.</span><span class="n">fd_step_type</span> <span class="o">=</span> <span class="s">&#39;relative&#39;</span>
</pre></div>
</div>
<p>you can also specify it on a specific model inputs:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">Float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">iotype</span><span class="o">=</span><span class="s">&#39;in&#39;</span><span class="p">,</span> <span class="n">fd_step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">fd_form</span> <span class="o">=</span> <span class="s">&#39;complex_step&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">iotype</span><span class="o">=</span><span class="s">&#39;in&#39;</span><span class="p">,</span> <span class="n">fd_step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<a href="http://openmdao.org">
 <img src="../../_static/OpenMDAO_Logo_200w_padded.png"
border="0" alt="OpenMDAO Home"/>
</a>

  <h3><a href="../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Adding Derivatives to Your Components</a><ul>
<li><a class="reference internal" href="#benchmarking"><em>Benchmarking</em></a></li>
<li><a class="reference internal" href="#finite-difference"><em>Finite Difference</em></a></li>
<li><a class="reference internal" href="#complex-step"><em>Complex Step</em></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="case_recorders.html"
                        title="previous chapter">Recording Your Inputs and Outputs</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="optimizers.html"
                        title="next chapter">Choosing an Optimizer</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../../_sources/tutorials/optimization/derivatives.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="optimizers.html" title="Choosing an Optimizer"
             >next</a> |</li>
        <li class="right" >
          <a href="case_recorders.html" title="Recording Your Inputs and Outputs"
             >previous</a> |</li>
  <li><a href="http://openmdao.org">OpenMDAO Home</a> &raquo;</li>
  
        <li><a href="../../index.html">OpenMDAO Documentation v0.13.0</a> &raquo;</li>

          <li><a href="../index.html" >OpenMDAO Tutorials</a> &raquo;</li>
          <li><a href="index.html" >Simple Optimization</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright none.
      Last updated on Apr 23, 2015.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>